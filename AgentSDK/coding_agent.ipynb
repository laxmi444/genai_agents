{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Coding System\n",
    "In this notebook, we will explore the concept of a multi-agent coding system. This system is designed to work with multiple agents, each capable of performing specific tasks. The agents will collaborate to solve complex problems and achieve their goals.\n",
    "\n",
    "The implementation uses OpenAI's API to create three specialized agents:\n",
    "\n",
    "1. Code Writer Agent : Transforms natural language descriptions into functional Python code, allowing users to quickly generate code snippets based on their requirements.\n",
    "2. Debugger Agent : Analyzes generated code to identify potential issues, bugs, and areas for improvement, providing detailed feedback similar to a code review.\n",
    "3. Documenter Agent : Creates comprehensive documentation for code snippets, making it easier to understand and maintain the generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting Up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports and setup\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import functools\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Callable, List\n",
    "from openai import OpenAI\n",
    "\n",
    "# apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MCP Framework\n",
    "\n",
    "This cell defines the Model Context Protocol (MCP) class, which provides a standardized way for AI agents to communicate:\n",
    "\n",
    "- The @mcp.tool decorator transforms regular methods into MCP-compliant agent tools\n",
    "- It uses Python's introspection capabilities ( inspect.signature() ) to analyze function parameters\n",
    "- The decorator creates a context dictionary containing agent name, task description, expected format, and parameters\n",
    "- String formatting is used to populate task description templates with actual parameter values\n",
    "- functools.wraps preserves the original function's metadata\n",
    "- The context is passed to the wrapped function, enabling consistent tracking of agent activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Model Context Protocol (MCP) Implementation\n",
    "class MCP:\n",
    "    \"\"\"Model Context Protocol module for standardized agent communication.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def tool(\n",
    "        task_description: str,\n",
    "        required_format: str = \"json\"\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Decorator for functions that use the Model Context Protocol.\n",
    "        \n",
    "        Args:\n",
    "            task_description (str): Template string describing the task\n",
    "            required_format (str): Expected response format\n",
    "            \n",
    "        Returns:\n",
    "            Callable: Decorated function\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable) -> Callable:\n",
    "            @functools.wraps(func)\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                # Get function arguments\n",
    "                import inspect\n",
    "                sig = inspect.signature(func)\n",
    "                bound_args = sig.bind(self, *args, **kwargs)\n",
    "                bound_args.apply_defaults()\n",
    "                \n",
    "                # Create context from arguments\n",
    "                arg_dict = dict(bound_args.arguments)\n",
    "                arg_dict.pop('self', None)  # Remove 'self' from context\n",
    "                \n",
    "                # Generate task description with arguments\n",
    "                formatted_task = task_description.format(**arg_dict)\n",
    "                \n",
    "                # Create a context dictionary\n",
    "                context = {\n",
    "                    \"agent\": self.name if hasattr(self, 'name') else type(self).__name__,\n",
    "                    \"task\": formatted_task,\n",
    "                    \"format\": required_format,\n",
    "                    \"parameters\": arg_dict\n",
    "                }\n",
    "                \n",
    "                # Call the original function with the context\n",
    "                return func(self, *args, **kwargs, mcp_context=context)\n",
    "            return wrapper\n",
    "        return decorator\n",
    "\n",
    "# Create an instance of the MCP module\n",
    "mcp = MCP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MCP Server Infrastructure\n",
    "Implements the base MCPServer class that provides the infrastructure for tool registration and execution:\n",
    "\n",
    "- The server maintains a dictionary of tools, each with metadata like name, description, and parameters\n",
    "- register_tool() allows adding new tools to the server with their specifications\n",
    "- call_tool() provides an asynchronous way to execute tools by name with parameter validation\n",
    "- list_tools() returns all available tools for discovery\n",
    "- The class includes placeholder methods for connection and cleanup, which could be extended for actual server implementations\n",
    "- This design follows a service-oriented architecture where tools are registered services that can be discovered and called\n",
    "\n",
    "#### Agent Workflow\n",
    "1. Code Writer Agent\n",
    "   \n",
    "   - Takes a natural language prompt\n",
    "   - Generates Python code using OpenAI\n",
    "   - Stores the code as an artifact in the context\n",
    "\n",
    "2. Debugger Agent\n",
    "   \n",
    "   - Analyzes code with awareness of the original task\n",
    "   - Produces a debugging report\n",
    "   - Maintains context from the code generation step\n",
    "   \n",
    "3. Documenter Agent\n",
    "   \n",
    "   - Creates documentation with access to both code and debug report\n",
    "   - Leverages the full context history for comprehensive documentation\n",
    "   - Stores documentation as a new artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Server Base Class\n",
    "class MCPServer:\n",
    "    \"\"\"Base class for MCP servers that follows the Model Context Protocol specification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the MCP server.\"\"\"\n",
    "        self._tools = {}\n",
    "        self._server_name = \"mcp_server\"\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Return the name of the server.\"\"\"\n",
    "        return self._server_name\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Connect to the server.\"\"\"\n",
    "        # No actual connection needed for this example\n",
    "        return True\n",
    "    \n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        # No cleanup needed for this example\n",
    "        pass\n",
    "    \n",
    "    def register_tool(self, tool_name, tool_desc, tool_func, parameters, required=None):\n",
    "        \"\"\"Register a tool with the server.\"\"\"\n",
    "        if required is None:\n",
    "            required = []\n",
    "            \n",
    "        self._tools[tool_name] = {\n",
    "            \"name\": tool_name,\n",
    "            \"description\": tool_desc,\n",
    "            \"function\": tool_func,\n",
    "            \"parameters\": parameters,\n",
    "            \"required\": required\n",
    "        }\n",
    "    \n",
    "    async def call_tool(self, tool_name, params):\n",
    "        \"\"\"Call a tool by name with parameters.\"\"\"\n",
    "        if tool_name not in self._tools:\n",
    "            raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "        \n",
    "        tool = self._tools[tool_name]\n",
    "        \n",
    "        # Check required parameters\n",
    "        for param in tool[\"required\"]:\n",
    "            if param not in params:\n",
    "                raise ValueError(f\"Missing required parameter: {param} for tool {tool_name}\")\n",
    "        \n",
    "        # Call the function\n",
    "        func = tool[\"function\"]\n",
    "        return func(params)\n",
    "    \n",
    "    async def list_tools(self):\n",
    "        \"\"\"List all registered tools.\"\"\"\n",
    "        return list(self._tools.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Specialized Coding Server Setup\n",
    "\n",
    "This cell begins the implementation of the CodingMCPServer, which specializes in coding-related tools:\n",
    "\n",
    "- It initializes with an OpenAI API key and creates an OpenAI client instance using the new SDK format\n",
    "- The server maintains a rich context structure with messages, artifacts, and metadata\n",
    "- A unique session ID is generated for tracking interactions\n",
    "- The _register_coding_tools() method sets up three specialized coding tools:\n",
    "  1. code_writer : Generates Python code from natural language descriptions\n",
    "  2. code_debugger : Analyzes code for issues and improvements\n",
    "  3. code_documenter : Creates documentation for code\n",
    "- Each tool registration includes detailed parameter specifications and requirements\n",
    "- This design follows a plugin architecture where specialized tools can be easily added to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding MCP Server Implementation - Part 1 (Setup and Registration)\n",
    "class CodingMCPServer(MCPServer):\n",
    "    \"\"\"MCP Server implementation specifically for coding tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key):\n",
    "        \"\"\"Initialize the coding MCP server.\"\"\"\n",
    "        super().__init__()\n",
    "        self._server_name = \"coding_server\"\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        self.client = OpenAI(api_key=openai_api_key)  # Create OpenAI client\n",
    "        \n",
    "        # Initialize context\n",
    "        self.context = {\n",
    "            \"messages\": [],\n",
    "            \"artifacts\": {},\n",
    "            \"metadata\": {\n",
    "                \"version\": \"1.0\",\n",
    "                \"session_id\": str(uuid.uuid4())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Register coding tools\n",
    "        self._register_coding_tools()\n",
    "    \n",
    "    def _register_coding_tools(self):\n",
    "        \"\"\"Register all coding tools with the server.\"\"\"\n",
    "        # Code Writer Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_writer\",\n",
    "            tool_desc=\"Generates Python code from natural language descriptions\",\n",
    "            tool_func=self._generate_code,\n",
    "            parameters={\n",
    "                \"prompt\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Natural language description of the code to generate\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"prompt\"]\n",
    "        )\n",
    "        \n",
    "        # Debug Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_debugger\",\n",
    "            tool_desc=\"Analyzes Python code to identify issues and improvements\",\n",
    "            tool_func=self._debug_code,\n",
    "            parameters={\n",
    "                \"code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Python code to debug\"\n",
    "                },\n",
    "                \"task_description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Original task description\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"code\"]\n",
    "        )\n",
    "        \n",
    "        # Documenter Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_documenter\",\n",
    "            tool_desc=\"Creates documentation for Python code\",\n",
    "            tool_func=self._document_code,\n",
    "            parameters={\n",
    "                \"code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Python code to document\"\n",
    "                },\n",
    "                \"task_description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Original task description\"\n",
    "                },\n",
    "                \"debug_report\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Debug report for the code\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"code\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Context Management Methods\n",
    "\n",
    "This cell extends the CodingMCPServer with methods for managing context and preparing messages:\n",
    "\n",
    "- _update_context() : Records interactions between the user and assistant in the message history\n",
    "  - Each message includes role, content, timestamp, and optional artifact references\n",
    "  - This creates a chronological record of the conversation\n",
    "- _store_artifact() : Saves generated artifacts (code, debug reports, documentation) with metadata\n",
    "  - Each artifact has a unique ID, type, content, and creation timestamp\n",
    "  - This allows for referencing and retrieving artifacts throughout the session\n",
    "- _prepare_messages() : Formats messages for OpenAI API calls\n",
    "  - Includes a system prompt that defines the assistant's role\n",
    "  - Incorporates recent conversation history (limited to 5 messages for efficiency)\n",
    "  - Adds the current user prompt\n",
    "  - This context-aware approach enables more coherent and relevant responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding MCP Server Implementation - Part 2 (Context Management)\n",
    "class CodingMCPServer(CodingMCPServer):  # Continuing the class definition\n",
    "    def _update_context(self, role, content, artifact_id=None):\n",
    "        \"\"\"\n",
    "        Update the MCP context with new interactions\n",
    "        \n",
    "        Args:\n",
    "            role (str): The role of the message sender (user/assistant)\n",
    "            content (str): The content of the message\n",
    "            artifact_id (str, optional): ID of any generated artifact\n",
    "        \"\"\"\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        if artifact_id:\n",
    "            message[\"artifact_id\"] = artifact_id\n",
    "            \n",
    "        self.context[\"messages\"].append(message)\n",
    "        return message\n",
    "\n",
    "    def _store_artifact(self, artifact_id, artifact_type, content):\n",
    "        \"\"\"\n",
    "        Store artifacts in the MCP context\n",
    "        \n",
    "        Args:\n",
    "            artifact_id (str): Unique identifier for the artifact\n",
    "            artifact_type (str): Type of artifact (code/debug/doc)\n",
    "            content (str): The artifact content\n",
    "        \"\"\"\n",
    "        self.context[\"artifacts\"][artifact_id] = {\n",
    "            \"type\": artifact_type,\n",
    "            \"content\": content,\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        return artifact_id\n",
    "\n",
    "    def _prepare_messages(self, system_prompt, user_prompt):\n",
    "        \"\"\"\n",
    "        Prepare messages for OpenAI API calls\n",
    "        \n",
    "        Args:\n",
    "            system_prompt (str): The system prompt\n",
    "            user_prompt (str): The user prompt\n",
    "            \n",
    "        Returns:\n",
    "            list: Messages formatted for OpenAI API\n",
    "        \"\"\"\n",
    "        # Create messages list with system prompt\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        \n",
    "        # Add context messages (limited to last 5 for efficiency)\n",
    "        for msg in self.context[\"messages\"][-5:]:\n",
    "            messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
    "            \n",
    "        # Add the current user prompt\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        \n",
    "        return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. AI-Powered Tool Functions\n",
    "\n",
    "This cell implements the core AI-powered tool functions for the CodingMCPServer:\n",
    "\n",
    "- _generate_code() : Transforms natural language descriptions into Python code\n",
    "  - Uses a specialized system prompt to guide the AI's role as a code writer\n",
    "  - Formats the user's prompt to focus on code generation without explanations\n",
    "  - Stores the generated code as an artifact and updates the conversation context\n",
    "- _debug_code() : Analyzes code to identify issues and improvements\n",
    "  - Takes code and optional task description as input\n",
    "  - Uses a system prompt that positions the AI as a senior software engineer\n",
    "  - Provides context about the original task to ensure relevant debugging\n",
    "  - Stores the debug report as an artifact for future reference\n",
    "- _document_code() : Creates comprehensive documentation for code\n",
    "  - Takes code, optional task description, and optional debug report\n",
    "  - Uses a system prompt that positions the AI as a documentation expert\n",
    "  - Incorporates the original task and debug findings for context-aware documentation\n",
    "  - Stores the documentation as an artifact\n",
    "- All functions use the new OpenAI API format with the client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Coding MCP Server Implementation - Part 3 (Tool Functions)\n",
    "class CodingMCPServer(CodingMCPServer):  # Continuing the class definition\n",
    "    def _generate_code(self, params):\n",
    "        \"\"\"Generate code using OpenAI API.\"\"\"\n",
    "        prompt = params[\"prompt\"]\n",
    "        \n",
    "        # Update context with user request\n",
    "        self._update_context(\"user\", prompt)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a professional Python code writer.\"\n",
    "        user_content = f\"Write a Python function for: {prompt}. Provide only the code, no explanations.\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        code = response.choices[0].message.content\n",
    "        \n",
    "        # Store the code as an artifact and update context\n",
    "        artifact_id = f\"code_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"code\", code)\n",
    "        self._update_context(\"assistant\", code, artifact_id)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def _debug_code(self, params):\n",
    "        \"\"\"Debug code using OpenAI API.\"\"\"\n",
    "        code = params[\"code\"]\n",
    "        task_description = params.get(\"task_description\")\n",
    "        \n",
    "        # Add debug request to context\n",
    "        debug_request = f\"Debug the following code\"\n",
    "        if task_description:\n",
    "            debug_request += f\" for task: {task_description}\"\n",
    "        self._update_context(\"user\", debug_request)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a senior software engineer and code debugger.\"\n",
    "        user_content = f\"Review this Python code and identify potential issues:\\n{code}\"\n",
    "        if task_description:\n",
    "            user_content = f\"This code was written for: {task_description}. {user_content}\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        debug_report = response.choices[0].message.content\n",
    "        \n",
    "        # Store the debug report as an artifact and update context\n",
    "        artifact_id = f\"debug_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"debug_report\", debug_report)\n",
    "        self._update_context(\"assistant\", debug_report, artifact_id)\n",
    "        \n",
    "        return debug_report\n",
    "    \n",
    "    def _document_code(self, params):\n",
    "        \"\"\"Generate documentation using OpenAI API.\"\"\"\n",
    "        code = params[\"code\"]\n",
    "        task_description = params.get(\"task_description\")\n",
    "        debug_report = params.get(\"debug_report\")\n",
    "        \n",
    "        # Add documentation request to context\n",
    "        doc_request = \"Create documentation for the code\"\n",
    "        self._update_context(\"user\", doc_request)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a technical documentation expert.\"\n",
    "        user_content = f\"Create comprehensive documentation for this Python code:\\n{code}\"\n",
    "        \n",
    "        # Add relevant context to the message content\n",
    "        if task_description:\n",
    "            user_content = f\"This code was written for: {task_description}. {user_content}\"\n",
    "        \n",
    "        # Reference debug report if available\n",
    "        if debug_report:\n",
    "            user_content = f\"A debug report is available: {debug_report}\\nPlease consider its findings when documenting. {user_content}\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        documentation = response.choices[0].message.content\n",
    "        \n",
    "        # Store the documentation as an artifact and update context\n",
    "        artifact_id = f\"doc_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"documentation\", documentation)\n",
    "        self._update_context(\"assistant\", documentation, artifact_id)\n",
    "        \n",
    "        return documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Agent Interface Layer\n",
    "\n",
    "This cell implements the CodingAgents class, which serves as the user-facing interface to the coding tools:\n",
    "\n",
    "- The class initializes with an OpenAI API key and sets up the MCP server\n",
    "- It uses an event loop for handling asynchronous operations with the server\n",
    "- The __del__ method ensures proper cleanup of resources when the object is destroyed\n",
    "- Three MCP-decorated agent methods provide the main functionality:\n",
    "  1. code_writer_agent : Transforms natural language into Python code\n",
    "     - Decorated with task description \"Generate Python code for: {prompt}\"\n",
    "     - Expected to return code format\n",
    "  2. debugger_agent : Analyzes code for issues and improvements\n",
    "     - Decorated with task description \"Debug Python code for task: {task_description}\"\n",
    "     - Expected to return a report format\n",
    "  3. documenter_agent : Creates documentation for code\n",
    "     - Decorated with task description \"Document Python code for task: {task_description}\"\n",
    "     - Expected to return markdown format\n",
    "- Each agent method delegates to the corresponding tool in the MCP server\n",
    "- The MCP decorators automatically track context and format task descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodingAgents Class Implementation\n",
    "class CodingAgents:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the coding agents with OpenAI API and MCP server\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): OpenAI API key\n",
    "        \"\"\"\n",
    "        # Setup basic properties\n",
    "        self.openai_api_key = api_key  # Store API key directly\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        self.name = \"CodingAssistant\"\n",
    "        \n",
    "        # Initialize MCP server and connect\n",
    "        self.server = CodingMCPServer(api_key)\n",
    "        \n",
    "        # Set up event loop for async operations\n",
    "        self.loop = asyncio.get_event_loop()\n",
    "        \n",
    "        # Connect to the MCP server\n",
    "        self.loop.run_until_complete(self.server.connect())\n",
    "        \n",
    "        # Use the server's context for continuity\n",
    "        self.context = self.server.context\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up resources when the object is destroyed.\"\"\"\n",
    "        # Make sure we clean up the server when done\n",
    "        try:\n",
    "            self.loop.run_until_complete(self.server.cleanup())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    @mcp.tool(\n",
    "        task_description=\"Generate Python code for: {prompt}\",\n",
    "        required_format=\"code\"\n",
    "    )\n",
    "    def code_writer_agent(self, prompt, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Generate code using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): Coding task description\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Generated code\n",
    "        \"\"\"\n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_writer\", {\"prompt\": prompt})\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    @mcp.tool(\n",
    "        task_description=\"Debug Python code for task: {task_description}\",\n",
    "        required_format=\"report\"\n",
    "    )\n",
    "    def debugger_agent(self, code, task_description=None, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Debug code using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            code (str): Code to debug\n",
    "            task_description (str, optional): Original task description for context\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Debugging report\n",
    "        \"\"\"\n",
    "        # Prepare parameters\n",
    "        params = {\n",
    "            \"code\": code\n",
    "        }\n",
    "        if task_description:\n",
    "            params[\"task_description\"] = task_description\n",
    "        \n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_debugger\", params)\n",
    "        )\n",
    "        return result\n",
    "        \n",
    "    @mcp.tool(\n",
    "        task_description=\"Document Python code for task: {task_description}\",\n",
    "        required_format=\"markdown\"\n",
    "    )\n",
    "    def documenter_agent(self, code, task_description=None, debug_report=None, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Generate documentation using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            code (str): Code to document\n",
    "            task_description (str, optional): Original task description\n",
    "            debug_report (str, optional): Debug report for context\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Documentation\n",
    "        \"\"\"\n",
    "        # Prepare parameters\n",
    "        params = {\n",
    "            \"code\": code\n",
    "        }\n",
    "        if task_description:\n",
    "            params[\"task_description\"] = task_description\n",
    "        if debug_report:\n",
    "            params[\"debug_report\"] = debug_report\n",
    "        \n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_documenter\", params)\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running MCP for task: Create a function that calculates the factorial of a number\n",
      "\n",
      "ðŸ“ Generated Code:\n",
      "```python\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial(n-1)\n",
      "```\n",
      "```\n",
      "\n",
      "ðŸž Debug Report:\n",
      "The code you provided looks correct at first glance for calculating the factorial of a number. However, there are potential issues that you should consider:\n",
      "\n",
      "1. Input validation: The current implementation assumes that the input 'n' is a non-negative integer. If a negative integer or a non-integer value is passed as input, it might result in unexpected behavior or an infinite loop.\n",
      "2. Recursion depth limit: Using recursion for calculating factorials can lead to hitting the maximum recursion depth in Python for very large input values. Consider using an iterative approach for handling large values.\n",
      "\n",
      "To address these potential issues, you may consider adding input validation checks and implementing an iterative version of the factorial function to handle large input values more efficiently. Let me know if you need help with any modifications.\n",
      "\n",
      "ðŸ“„ Documentation:\n",
      "## Function: Calculate Factorial\n",
      "\n",
      "This function calculates the factorial of a given non-negative integer using recursion.\n",
      "\n",
      "#### Parameters:\n",
      "- `n`: A non-negative integer for which the factorial needs to be calculated.\n",
      "\n",
      "#### Return Value:\n",
      "- The factorial of the input integer `n`.\n",
      "\n",
      "#### Known Issues:\n",
      "1. **Input Validation**: The current implementation assumes that the input `n` is a non-negative integer. Passing a negative integer or a non-integer value might lead to unexpected behavior or an infinite loop.\n",
      "2. **Recursion Depth Limit**: Using recursion for calculating factorials can result in hitting the maximum recursion depth in Python for very large input values.\n",
      "\n",
      "#### Suggestions for Modification:\n",
      "- Implement input validation checks to ensure `n` is a non-negative integer.\n",
      "- Consider an iterative approach for handling large input values to avoid recursion depth issues.\n",
      "\n",
      "#### Example Usage:\n",
      "```python\n",
      "result = factorial(5)\n",
      "print(result)  # Output: 120\n",
      "```\n",
      "\n",
      "It is advised to consider the input validation and potential recursion depth issues when using this function in production code.\n",
      "\n",
      "ðŸ§  Context Summary:\n",
      "Session ID: 6d6a0df3-b398-4655-958e-12ad309198ff\n",
      "Messages: 6\n",
      "Artifacts: 3\n",
      "Available MCP Tools: 3\n",
      "  - code_writer: Generates Python code from natural language descriptions\n",
      "  - code_debugger: Analyzes Python code to identify issues and improvements\n",
      "  - code_documenter: Creates documentation for Python code\n"
     ]
    }
   ],
   "source": [
    "# demo Function\n",
    "def run_mcp_coding_demo():\n",
    "    # Get API key from environment variable\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"Please set OPENAI_API_KEY environment variable\")\n",
    "        return\n",
    "    \n",
    "    # Initialize the agents with MCP\n",
    "    agents = CodingAgents(api_key)\n",
    "    \n",
    "    # Example task\n",
    "    task = \"Create a function that calculates the factorial of a number\"\n",
    "    \n",
    "    print(f\"ðŸš€ Running MCP for task: {task}\")\n",
    "    \n",
    "    # Process the task with Model Context Protocol\n",
    "    code = agents.code_writer_agent(task)\n",
    "    print(\"\\nðŸ“ Generated Code:\")\n",
    "    print(f\"```python\\n{code}\\n```\")\n",
    "    \n",
    "    debug_report = agents.debugger_agent(code, task)\n",
    "    print(\"\\nðŸž Debug Report:\")\n",
    "    print(debug_report)\n",
    "    \n",
    "    documentation = agents.documenter_agent(code, task, debug_report)\n",
    "    print(\"\\nðŸ“„ Documentation:\")\n",
    "    print(documentation)\n",
    "    \n",
    "    # List all available tools via the MCP server\n",
    "    tools = agents.loop.run_until_complete(agents.server.list_tools())\n",
    "    \n",
    "    print(\"\\nðŸ§  Context Summary:\")\n",
    "    print(f\"Session ID: {agents.context['metadata']['session_id']}\")\n",
    "    print(f\"Messages: {len(agents.context['messages'])}\")\n",
    "    print(f\"Artifacts: {len(agents.context['artifacts'])}\")\n",
    "    print(f\"Available MCP Tools: {len(tools)}\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool['name']}: {tool['description']}\")\n",
    "\n",
    "# Run the demo if executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    run_mcp_coding_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running MCP for task: Create a function that calculates the factorial of a number\n",
      "\n",
      "ðŸ“ Generated Code:\n",
      "```python\n",
      "```python\n",
      "def factorial(num):\n",
      "    if num == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return num * factorial(num - 1)\n",
      "```\n",
      "```\n",
      "\n",
      "ðŸž Debug Report:\n",
      "The provided code for calculating the factorial of a number looks correct and should work as expected. The base case is properly handled when num equals 0, and the recursive call correctly calculates the factorial for num - 1 until the base case is reached.\n",
      "\n",
      "However, it's important to note that this implementation may encounter a \"RecursionError\" for very large values of num due to exceeding the maximum recursion depth in Python. You may want to consider using a non-recursive approach or use tail recursion optimization if handling large values is a concern.\n",
      "\n",
      "ðŸ“„ Documentation:\n",
      "### Function: factorial\n",
      "\n",
      "This Python function calculates the factorial of a given number.\n",
      "\n",
      "#### Parameters:\n",
      "- `num`: An integer representing the number for which the factorial needs to be calculated.\n",
      "\n",
      "#### Returns:\n",
      "- An integer representing the factorial of the input number.\n",
      "\n",
      "#### Error Handling:\n",
      "- The function may encounter a \"RecursionError\" for very large values of `num` due to exceeding the maximum recursion depth in Python. To avoid this, for extremely large values, consider using a non-recursive approach or implementing tail recursion optimization.\n",
      "\n",
      "#### Usage Example:\n",
      "```python\n",
      "result = factorial(5)\n",
      "print(result)  # Output: 120\n",
      "\n",
      "result = factorial(0)\n",
      "print(result)  # Output: 1\n",
      "```\n",
      "\n",
      "### Important Note:\n",
      "- When using this function with very large values or in a resource-constrained environment, be cautious about potential recursion errors and consider alternatives for handling extreme cases.\n",
      "\n",
      "ðŸ§  Context Summary:\n",
      "Session ID: 93c3a7c7-4f0c-406a-9d20-9930e629f829\n",
      "Messages: 6\n",
      "Artifacts: 3\n",
      "Available MCP Tools: 3\n",
      "  - code_writer: Generates Python code from natural language descriptions\n",
      "  - code_debugger: Analyzes Python code to identify issues and improvements\n",
      "  - code_documenter: Creates documentation for Python code\n"
     ]
    }
   ],
   "source": [
    "# Multi-Agent Coding System with Proper MCP Integration\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import uuid\n",
    "import functools\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Callable, List\n",
    "from openai import OpenAI\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "class MCP:\n",
    "    \"\"\"Model Context Protocol module for standardized agent communication.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def tool(\n",
    "        task_description: str,\n",
    "        required_format: str = \"json\"\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Decorator for functions that use the Model Context Protocol.\n",
    "        \n",
    "        Args:\n",
    "            task_description (str): Template string describing the task\n",
    "            required_format (str): Expected response format\n",
    "            \n",
    "        Returns:\n",
    "            Callable: Decorated function\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable) -> Callable:\n",
    "            @functools.wraps(func)\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                # Get function arguments\n",
    "                import inspect\n",
    "                sig = inspect.signature(func)\n",
    "                bound_args = sig.bind(self, *args, **kwargs)\n",
    "                bound_args.apply_defaults()\n",
    "                \n",
    "                # Create context from arguments\n",
    "                arg_dict = dict(bound_args.arguments)\n",
    "                arg_dict.pop('self', None)  # Remove 'self' from context\n",
    "                \n",
    "                # Generate task description with arguments\n",
    "                formatted_task = task_description.format(**arg_dict)\n",
    "                \n",
    "                # Create a context dictionary\n",
    "                context = {\n",
    "                    \"agent\": self.name if hasattr(self, 'name') else type(self).__name__,\n",
    "                    \"task\": formatted_task,\n",
    "                    \"format\": required_format,\n",
    "                    \"parameters\": arg_dict\n",
    "                }\n",
    "                \n",
    "                # Call the original function with the context\n",
    "                return func(self, *args, **kwargs, mcp_context=context)\n",
    "            return wrapper\n",
    "        return decorator\n",
    "\n",
    "# Create an instance of the MCP module\n",
    "mcp = MCP()\n",
    "\n",
    "# Define MCP Server base class\n",
    "class MCPServer:\n",
    "    \"\"\"Base class for MCP servers that follows the Model Context Protocol specification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the MCP server.\"\"\"\n",
    "        self._tools = {}\n",
    "        self._server_name = \"mcp_server\"\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Return the name of the server.\"\"\"\n",
    "        return self._server_name\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Connect to the server.\"\"\"\n",
    "        # No actual connection needed for this example\n",
    "        return True\n",
    "    \n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        # No cleanup needed for this example\n",
    "        pass\n",
    "    \n",
    "    def register_tool(self, tool_name, tool_desc, tool_func, parameters, required=None):\n",
    "        \"\"\"Register a tool with the server.\"\"\"\n",
    "        if required is None:\n",
    "            required = []\n",
    "            \n",
    "        self._tools[tool_name] = {\n",
    "            \"name\": tool_name,\n",
    "            \"description\": tool_desc,\n",
    "            \"function\": tool_func,\n",
    "            \"parameters\": parameters,\n",
    "            \"required\": required\n",
    "        }\n",
    "    \n",
    "    async def call_tool(self, tool_name, params):\n",
    "        \"\"\"Call a tool by name with parameters.\"\"\"\n",
    "        if tool_name not in self._tools:\n",
    "            raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "        \n",
    "        tool = self._tools[tool_name]\n",
    "        \n",
    "        # Check required parameters\n",
    "        for param in tool[\"required\"]:\n",
    "            if param not in params:\n",
    "                raise ValueError(f\"Missing required parameter: {param} for tool {tool_name}\")\n",
    "        \n",
    "        # Call the function\n",
    "        func = tool[\"function\"]\n",
    "        return func(params)\n",
    "    \n",
    "    async def list_tools(self):\n",
    "        \"\"\"List all registered tools.\"\"\"\n",
    "        return list(self._tools.values())\n",
    "\n",
    "# Coding MCP Server implementation\n",
    "class CodingMCPServer(MCPServer):\n",
    "    \"\"\"MCP Server implementation specifically for coding tools.\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key):\n",
    "        \"\"\"Initialize the coding MCP server.\"\"\"\n",
    "        super().__init__()\n",
    "        self._server_name = \"coding_server\"\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        self.client = OpenAI(api_key=openai_api_key)  # Create OpenAI client\n",
    "        \n",
    "        # Initialize context\n",
    "        self.context = {\n",
    "            \"messages\": [],\n",
    "            \"artifacts\": {},\n",
    "            \"metadata\": {\n",
    "                \"version\": \"1.0\",\n",
    "                \"session_id\": str(uuid.uuid4())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Register coding tools\n",
    "        self._register_coding_tools()\n",
    "    \n",
    "    def _register_coding_tools(self):\n",
    "        \"\"\"Register all coding tools with the server.\"\"\"\n",
    "        # Code Writer Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_writer\",\n",
    "            tool_desc=\"Generates Python code from natural language descriptions\",\n",
    "            tool_func=self._generate_code,\n",
    "            parameters={\n",
    "                \"prompt\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Natural language description of the code to generate\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"prompt\"]\n",
    "        )\n",
    "        \n",
    "        # Debug Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_debugger\",\n",
    "            tool_desc=\"Analyzes Python code to identify issues and improvements\",\n",
    "            tool_func=self._debug_code,\n",
    "            parameters={\n",
    "                \"code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Python code to debug\"\n",
    "                },\n",
    "                \"task_description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Original task description\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"code\"]\n",
    "        )\n",
    "        \n",
    "        # Documenter Tool\n",
    "        self.register_tool(\n",
    "            tool_name=\"code_documenter\",\n",
    "            tool_desc=\"Creates documentation for Python code\",\n",
    "            tool_func=self._document_code,\n",
    "            parameters={\n",
    "                \"code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Python code to document\"\n",
    "                },\n",
    "                \"task_description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Original task description\"\n",
    "                },\n",
    "                \"debug_report\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Debug report for the code\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"code\"]\n",
    "        )\n",
    "    \n",
    "    def _update_context(self, role, content, artifact_id=None):\n",
    "        \"\"\"\n",
    "        Update the MCP context with new interactions\n",
    "        \n",
    "        Args:\n",
    "            role (str): The role of the message sender (user/assistant)\n",
    "            content (str): The content of the message\n",
    "            artifact_id (str, optional): ID of any generated artifact\n",
    "        \"\"\"\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        if artifact_id:\n",
    "            message[\"artifact_id\"] = artifact_id\n",
    "            \n",
    "        self.context[\"messages\"].append(message)\n",
    "        return message\n",
    "\n",
    "    def _store_artifact(self, artifact_id, artifact_type, content):\n",
    "        \"\"\"\n",
    "        Store artifacts in the MCP context\n",
    "        \n",
    "        Args:\n",
    "            artifact_id (str): Unique identifier for the artifact\n",
    "            artifact_type (str): Type of artifact (code/debug/doc)\n",
    "            content (str): The artifact content\n",
    "        \"\"\"\n",
    "        self.context[\"artifacts\"][artifact_id] = {\n",
    "            \"type\": artifact_type,\n",
    "            \"content\": content,\n",
    "            \"created_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        return artifact_id\n",
    "\n",
    "    def _prepare_messages(self, system_prompt, user_prompt):\n",
    "        \"\"\"\n",
    "        Prepare messages for OpenAI API calls\n",
    "        \n",
    "        Args:\n",
    "            system_prompt (str): The system prompt\n",
    "            user_prompt (str): The user prompt\n",
    "            \n",
    "        Returns:\n",
    "            list: Messages formatted for OpenAI API\n",
    "        \"\"\"\n",
    "        # Create messages list with system prompt\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        \n",
    "        # Add context messages (limited to last 5 for efficiency)\n",
    "        for msg in self.context[\"messages\"][-5:]:\n",
    "            messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
    "            \n",
    "        # Add the current user prompt\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "        \n",
    "        return messages\n",
    "    \n",
    "    def _generate_code(self, params):\n",
    "        \"\"\"Generate code using OpenAI API.\"\"\"\n",
    "        prompt = params[\"prompt\"]\n",
    "        \n",
    "        # Update context with user request\n",
    "        self._update_context(\"user\", prompt)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a professional Python code writer.\"\n",
    "        user_content = f\"Write a Python function for: {prompt}. Provide only the code, no explanations.\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        code = response.choices[0].message.content\n",
    "        \n",
    "        # Store the code as an artifact and update context\n",
    "        artifact_id = f\"code_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"code\", code)\n",
    "        self._update_context(\"assistant\", code, artifact_id)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def _debug_code(self, params):\n",
    "        \"\"\"Debug code using OpenAI API.\"\"\"\n",
    "        code = params[\"code\"]\n",
    "        task_description = params.get(\"task_description\")\n",
    "        \n",
    "        # Add debug request to context\n",
    "        debug_request = f\"Debug the following code\"\n",
    "        if task_description:\n",
    "            debug_request += f\" for task: {task_description}\"\n",
    "        self._update_context(\"user\", debug_request)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a senior software engineer and code debugger.\"\n",
    "        user_content = f\"Review this Python code and identify potential issues:\\n{code}\"\n",
    "        if task_description:\n",
    "            user_content = f\"This code was written for: {task_description}. {user_content}\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        debug_report = response.choices[0].message.content\n",
    "        \n",
    "        # Store the debug report as an artifact and update context\n",
    "        artifact_id = f\"debug_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"debug_report\", debug_report)\n",
    "        self._update_context(\"assistant\", debug_report, artifact_id)\n",
    "        \n",
    "        return debug_report\n",
    "    \n",
    "    def _document_code(self, params):\n",
    "        \"\"\"Generate documentation using OpenAI API.\"\"\"\n",
    "        code = params[\"code\"]\n",
    "        task_description = params.get(\"task_description\")\n",
    "        debug_report = params.get(\"debug_report\")\n",
    "        \n",
    "        # Add documentation request to context\n",
    "        doc_request = \"Create documentation for the code\"\n",
    "        self._update_context(\"user\", doc_request)\n",
    "        \n",
    "        # Prepare MCP-formatted messages\n",
    "        system_prompt = \"You are a technical documentation expert.\"\n",
    "        user_content = f\"Create comprehensive documentation for this Python code:\\n{code}\"\n",
    "        \n",
    "        # Add relevant context to the message content\n",
    "        if task_description:\n",
    "            user_content = f\"This code was written for: {task_description}. {user_content}\"\n",
    "        \n",
    "        # Reference debug report if available\n",
    "        if debug_report:\n",
    "            user_content = f\"A debug report is available: {debug_report}\\nPlease consider its findings when documenting. {user_content}\"\n",
    "        \n",
    "        messages = self._prepare_messages(system_prompt, user_content)\n",
    "        \n",
    "        # Send request with OpenAI API using new format\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            user=self.context[\"metadata\"][\"session_id\"]\n",
    "        )\n",
    "        \n",
    "        documentation = response.choices[0].message.content\n",
    "        \n",
    "        # Store the documentation as an artifact and update context\n",
    "        artifact_id = f\"doc_{len(self.context['artifacts']) + 1}\"\n",
    "        self._store_artifact(artifact_id, \"documentation\", documentation)\n",
    "        self._update_context(\"assistant\", documentation, artifact_id)\n",
    "        \n",
    "        return documentation\n",
    "\n",
    "class CodingAgents:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the coding agents with OpenAI API and MCP server\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): OpenAI API key\n",
    "        \"\"\"\n",
    "        # Setup basic properties\n",
    "class CodingAgents:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the coding agents with OpenAI API and MCP server\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): OpenAI API key\n",
    "        \"\"\"\n",
    "        # Setup basic properties\n",
    "        self.openai_api_key = api_key  # Store API key directly\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        self.name = \"CodingAssistant\"\n",
    "        \n",
    "        # Initialize MCP server and connect\n",
    "        self.server = CodingMCPServer(api_key)\n",
    "        \n",
    "        # Set up event loop for async operations\n",
    "        self.loop = asyncio.get_event_loop()\n",
    "        \n",
    "        # Connect to the MCP server\n",
    "        self.loop.run_until_complete(self.server.connect())\n",
    "        \n",
    "        # Use the server's context for continuity\n",
    "        self.context = self.server.context\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Clean up resources when the object is destroyed.\"\"\"\n",
    "        # Make sure we clean up the server when done\n",
    "        try:\n",
    "            self.loop.run_until_complete(self.server.cleanup())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    @mcp.tool(\n",
    "        task_description=\"Generate Python code for: {prompt}\",\n",
    "        required_format=\"code\"\n",
    "    )\n",
    "    def code_writer_agent(self, prompt, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Generate code using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): Coding task description\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Generated code\n",
    "        \"\"\"\n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_writer\", {\"prompt\": prompt})\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    @mcp.tool(\n",
    "        task_description=\"Debug Python code for task: {task_description}\",\n",
    "        required_format=\"report\"\n",
    "    )\n",
    "    def debugger_agent(self, code, task_description=None, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Debug code using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            code (str): Code to debug\n",
    "            task_description (str, optional): Original task description for context\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Debugging report\n",
    "        \"\"\"\n",
    "        # Prepare parameters\n",
    "        params = {\n",
    "            \"code\": code\n",
    "        }\n",
    "        if task_description:\n",
    "            params[\"task_description\"] = task_description\n",
    "        \n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_debugger\", params)\n",
    "        )\n",
    "        return result\n",
    "        \n",
    "    @mcp.tool(\n",
    "        task_description=\"Document Python code for task: {task_description}\",\n",
    "        required_format=\"markdown\"\n",
    "    )\n",
    "    def documenter_agent(self, code, task_description=None, debug_report=None, mcp_context=None):\n",
    "        \"\"\"\n",
    "        Generate documentation using OpenAI API with MCP\n",
    "        \n",
    "        Args:\n",
    "            code (str): Code to document\n",
    "            task_description (str, optional): Original task description\n",
    "            debug_report (str, optional): Debug report for context\n",
    "            mcp_context (Dict, optional): MCP context from decorator\n",
    "        \n",
    "        Returns:\n",
    "            str: Documentation\n",
    "        \"\"\"\n",
    "        # Prepare parameters\n",
    "        params = {\n",
    "            \"code\": code\n",
    "        }\n",
    "        if task_description:\n",
    "            params[\"task_description\"] = task_description\n",
    "        if debug_report:\n",
    "            params[\"debug_report\"] = debug_report\n",
    "        \n",
    "        # Use the MCP server to call the tool\n",
    "        result = self.loop.run_until_complete(\n",
    "            self.server.call_tool(\"code_documenter\", params)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "# Function to demonstrate the MCP-enhanced coding agents\n",
    "def run_mcp_coding_demo():\n",
    "    # Get API key from environment variable\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"Please set OPENAI_API_KEY environment variable\")\n",
    "        return\n",
    "    \n",
    "    # Initialize the agents with MCP\n",
    "    agents = CodingAgents(api_key)\n",
    "    \n",
    "    # Example task\n",
    "    task = \"Create a function that calculates the factorial of a number\"\n",
    "    \n",
    "    print(f\"ðŸš€ Running MCP for task: {task}\")\n",
    "    \n",
    "    # Process the task with Model Context Protocol\n",
    "    code = agents.code_writer_agent(task)\n",
    "    print(\"\\nðŸ“ Generated Code:\")\n",
    "    print(f\"```python\\n{code}\\n```\")\n",
    "    \n",
    "    debug_report = agents.debugger_agent(code, task)\n",
    "    print(\"\\nðŸž Debug Report:\")\n",
    "    print(debug_report)\n",
    "    \n",
    "    documentation = agents.documenter_agent(code, task, debug_report)\n",
    "    print(\"\\nðŸ“„ Documentation:\")\n",
    "    print(documentation)\n",
    "    \n",
    "    # List all available tools via the MCP server\n",
    "    tools = agents.loop.run_until_complete(agents.server.list_tools())\n",
    "    \n",
    "    print(\"\\nðŸ§  Context Summary:\")\n",
    "    print(f\"Session ID: {agents.context['metadata']['session_id']}\")\n",
    "    print(f\"Messages: {len(agents.context['messages'])}\")\n",
    "    print(f\"Artifacts: {len(agents.context['artifacts'])}\")\n",
    "    print(f\"Available MCP Tools: {len(tools)}\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool['name']}: {tool['description']}\")\n",
    "\n",
    "# Run the demo if executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    run_mcp_coding_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
