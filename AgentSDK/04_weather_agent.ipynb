{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Information Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Weather Information Agent is designed to interpret natural language weather-related queries, extract the location, fetch real-time weather data, and generate a user-friendly response.\n",
    "\n",
    "- Location Extraction: Uses OpenAI API to determine the location from user queries.\n",
    "\n",
    "- Weather Data Retrieval: Fetches real-time weather details such as temperature, humidity, wind speed, and cloud coverage using Weatherstack API.\n",
    "\n",
    "- Natural Language Response: Generates conversational weather descriptions using OpenAI’s language model.\n",
    "\n",
    "- Comprehensive Query Processing: Ensures an end-to-end flow from understanding the user’s question to delivering an insightful weather report.\n",
    "\n",
    "This agent provides an interactive and seamless weather update experience for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\omkar\\anaconda3\\lib\\site-packages (1.70.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\omkar\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\omkar\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\omkar\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent\n",
    "from agents.mcp import MCPServer\n",
    "from agents import function_tool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# set up API keys\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Weather Agent Class\n",
    "The WeatherAgent class is a Python implementation that provides weather information for a given location using natural language processing. It combines the OpenAI API for language understanding and the Weatherstack API for retrieving weather data.\n",
    "\n",
    "### Key Components\n",
    "#### Initialization\n",
    "- The class requires API keys for both Weatherstack and OpenAI services\n",
    "- These keys are used to authenticate API requests\n",
    "#### Methods \n",
    "\n",
    "**1. call_openai_api**\n",
    "- Makes requests to OpenAI's API\n",
    "- Sends messages in a specific format required by OpenAI\n",
    "- Returns the generated text response or None if an error occurs\n",
    "- Handles API errors and exceptions gracefully \n",
    "\n",
    "**2. extract_location**\n",
    "- Uses OpenAI to extract location information from a natural language query\n",
    "- Provides specific instructions to the AI to focus only on location extraction\n",
    "- Returns the extracted location name \n",
    "\n",
    "**3. get_weather_data**\n",
    "- Fetches current weather data from Weatherstack API for a specified location\n",
    "- Processes the API response to extract relevant weather information\n",
    "- Returns a structured dictionary with key weather metrics including:\n",
    "  - Location name and country\n",
    "  - Temperature and \"feels like\" temperature\n",
    "  - Humidity and wind speed\n",
    "  - Weather description and cloud cover\n",
    "\n",
    "**4. generate_weather_response**\n",
    "- Creates a natural language description of weather conditions\n",
    "- Uses OpenAI to convert structured weather data into conversational text\n",
    "- Returns a friendly, informative weather description \n",
    "\n",
    "**5. process_weather_query**\n",
    "- Orchestrates the entire weather information process\n",
    "- Extracts location from user query\n",
    "- Retrieves weather data for that location\n",
    "- Generates a natural language response\n",
    "- Handles errors at each step with appropriate fallback messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAgent:\n",
    "    def __init__(self, weather_api_key, openai_api_key):\n",
    "        \"\"\"\n",
    "        Initialize the Weather Agent with API keys.\n",
    "        \n",
    "        Args:\n",
    "            weather_api_key (str): API key for weather service\n",
    "            openai_api_key (str): API key for OpenAI\n",
    "        \"\"\"\n",
    "        self.weather_api_key = weather_api_key\n",
    "        self.openai_api_key = openai_api_key\n",
    "        self.conversation_context = {\n",
    "            \"last_location\": None,\n",
    "            \"last_weather_data\": None,\n",
    "            \"query_history\": []\n",
    "        }\n",
    "    \n",
    "    def call_openai_api(self, messages, model=\"gpt-3.5-turbo\"):\n",
    "        \"\"\"\n",
    "        Call OpenAI API directly using requests.\n",
    "        \n",
    "        Args:\n",
    "            messages (list): List of message objects\n",
    "            model (str): Model to use\n",
    "            \n",
    "        Returns:\n",
    "            str: Response content\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.openai_api_key}\"\n",
    "        }\n",
    "        \n",
    "        # Create the payload\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                \"https://api.openai.com/v1/chat/completions\",\n",
    "                headers=headers,\n",
    "                json=payload\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            else:\n",
    "                print(f\"Error calling OpenAI API: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Exception when calling OpenAI API: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_location(self, user_query):\n",
    "        \"\"\"\n",
    "        Extract location from user query using OpenAI.\n",
    "        \n",
    "        Args:\n",
    "            user_query (str): Natural language weather query\n",
    "        \n",
    "        Returns:\n",
    "            str: Extracted location name or None if no location is found\n",
    "        \"\"\"\n",
    "        # Add context from previous queries\n",
    "        context_prompt = \"\"\n",
    "        if self.conversation_context[\"last_location\"]:\n",
    "            context_prompt = f\"Previous location mentioned was {self.conversation_context['last_location']}. \"\n",
    "        \n",
    "        # Create system message with improved instructions\n",
    "        system_content = (\n",
    "            \"You are a location extraction assistant. Extract the specific city or location from the given query. \"\n",
    "            \"If the query doesn't mention a specific location but refers to a previous location, use that previous location. \"\n",
    "            \"If the query is asking a comparative question like 'Is it warmer than yesterday?' or a future question like \"\n",
    "            \"'Will I need an umbrella tomorrow?' without specifying a location, respond with 'USE_PREVIOUS_LOCATION'. \"\n",
    "            \"If no location is mentioned and there's no previous context, respond with 'NO_LOCATION'.\"\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": f\"{context_prompt}Extract the location from this query: '{user_query}'.\"}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            location = self.call_openai_api(messages)\n",
    "            \n",
    "            # Handle special responses\n",
    "            if location == \"USE_PREVIOUS_LOCATION\":\n",
    "                return self.conversation_context[\"last_location\"]\n",
    "            elif location == \"NO_LOCATION\":\n",
    "                return None\n",
    "            \n",
    "            # Store the location in context\n",
    "            self.conversation_context[\"last_location\"] = location\n",
    "            return location\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting location: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_weather_data(self, location):\n",
    "        \"\"\"\n",
    "        Fetch weather data for a given location using Weatherstack API.\n",
    "        \n",
    "        Args:\n",
    "            location (str): City name or location identifier\n",
    "        \n",
    "        Returns:\n",
    "            dict: Processed weather information\n",
    "        \"\"\"\n",
    "        base_url = \"http://api.weatherstack.com/current\"\n",
    "        params = {\n",
    "            'access_key': self.weather_api_key,\n",
    "            'query': location,\n",
    "            'units': 'm'  # Metric units\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params)\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check for errors in the response\n",
    "            if 'error' in data:\n",
    "                print(f\"Weather API error: {data['error']['info']}\")\n",
    "                return None\n",
    "            \n",
    "            # Extract relevant weather information\n",
    "            weather_info = {\n",
    "                'location': data['location']['name'],\n",
    "                'country': data['location']['country'],\n",
    "                'temperature': data['current']['temperature'],\n",
    "                'feels_like': data['current']['feelslike'],\n",
    "                'humidity': data['current']['humidity'],\n",
    "                'description': data['current']['weather_descriptions'][0] if data['current']['weather_descriptions'] else 'No description available',\n",
    "                'wind_speed': data['current']['wind_speed'],\n",
    "                'cloudiness': data['current']['cloudcover']\n",
    "            }\n",
    "            \n",
    "            # Store the weather data in context\n",
    "            self.conversation_context[\"last_weather_data\"] = weather_info\n",
    "            return weather_info\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching weather data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_weather_response(self, weather_data, user_query):\n",
    "        \"\"\"\n",
    "        Generate a natural language response for weather data.\n",
    "        \n",
    "        Args:\n",
    "            weather_data (dict): Weather information\n",
    "            user_query (str): Original user query\n",
    "        \n",
    "        Returns:\n",
    "            str: Descriptive weather response\n",
    "        \"\"\"\n",
    "        # Add context for comparative or future queries\n",
    "        context_prompt = \"\"\n",
    "        if \"yesterday\" in user_query.lower() or \"warmer\" in user_query.lower() or \"colder\" in user_query.lower():\n",
    "            context_prompt = \"This is a comparative question about temperature. \"\n",
    "        elif \"tomorrow\" in user_query.lower() or \"umbrella\" in user_query.lower() or \"rain\" in user_query.lower():\n",
    "            context_prompt = \"This is a question about future weather or precipitation. \"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a friendly weather narrator. Create a conversational weather description. {context_prompt}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Create a friendly, informative weather description for this query: '{user_query}' using this data: {weather_data}\"}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            response = self.call_openai_api(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating weather response: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_weather_query(self, user_query):\n",
    "        \"\"\"\n",
    "        Process a complete weather query from extraction to response.\n",
    "        \n",
    "        Args:\n",
    "            user_query (str): Natural language weather query\n",
    "        \n",
    "        Returns:\n",
    "            str: Comprehensive weather information response\n",
    "        \"\"\"\n",
    "        # Store query in history\n",
    "        self.conversation_context[\"query_history\"].append(user_query)\n",
    "        \n",
    "        # Extract location\n",
    "        location = self.extract_location(user_query)\n",
    "        if not location:\n",
    "            if self.conversation_context[\"last_location\"]:\n",
    "                # Use the last location if available\n",
    "                location = self.conversation_context[\"last_location\"]\n",
    "                print(f\"Using previous location: {location}\")\n",
    "            else:\n",
    "                return \"I need to know which location you're asking about. Could you specify a city or place?\"\n",
    "        \n",
    "        # Get weather data\n",
    "        weather_data = self.get_weather_data(location)\n",
    "        if not weather_data:\n",
    "            return f\"Sorry, I couldn't retrieve weather data for {location}.\"\n",
    "        \n",
    "        # Generate natural language response\n",
    "        weather_response = self.generate_weather_response(weather_data, user_query)\n",
    "        return weather_response or \"I encountered an issue generating the weather description.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create the MCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WeatherMCPServer class is an implementation of the Model-Control-Protocol (MCP) server that provides weather information services. Here's a description of its functionality:\n",
    "\n",
    "This class serves as a bridge between the Agent SDK framework and the custom WeatherAgent implementation. It handles the registration, discovery, and execution of weather-related tools that can be used by AI agents.\n",
    "\n",
    "Key components:\n",
    "\n",
    "1. **Initialization** : Creates a server instance with a weather agent, either using a provided agent or creating a new one with the configured API keys.\n",
    "2. **Server Properties** : Provides a unique name identifier (\"weather_server\") for the MCP framework to reference.\n",
    "3. **Connection Management** : Implements required connection methods ( connect and cleanup ) that handle server lifecycle, though in this implementation they're simplified since no actual external connection is needed.\n",
    "4. **Tool Execution** : The *call_tool* method routes incoming tool requests to the appropriate handler - in this case, it processes weather queries by delegating to the WeatherAgent .\n",
    "5. **Tool Registration** : The list_tools method exposes the available tools to the agent framework by creating a FunctionTool that describes the weather query capability, including its parameters and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP Server implementation for weather\n",
    "class WeatherMCPServer(MCPServer):\n",
    "    def __init__(self, weather_agent=None):\n",
    "        super().__init__()\n",
    "        self.weather_agent = weather_agent or WeatherAgent(\n",
    "            weather_api_key=WEATHER_API_KEY, \n",
    "            openai_api_key=OPENAI_API_KEY\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Return the name of the server.\"\"\"\n",
    "        return \"weather_server\"\n",
    "    \n",
    "    async def connect(self):\n",
    "        \"\"\"Connect to the server.\"\"\"\n",
    "        # No actual connection needed for this example\n",
    "        return True\n",
    "    \n",
    "    async def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        # No cleanup needed for this example\n",
    "        pass\n",
    "    \n",
    "    async def call_tool(self, tool_name, tool_params):\n",
    "        \"\"\"Call a tool by name with parameters.\"\"\"\n",
    "        if tool_name == \"weather_tool\":\n",
    "            return self.weather_agent.process_weather_query(tool_params[\"query\"])\n",
    "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
    "    \n",
    "    async def list_tools(self):\n",
    "        \"\"\"List available tools.\"\"\"\n",
    "        # Create a weather tool using function_tool module\n",
    "        weather_tool = function_tool.FunctionTool(\n",
    "            name=\"weather_tool\",\n",
    "            description=\"Get current weather information for a location\",\n",
    "            function=lambda params: self.weather_agent.process_weather_query(params[\"query\"]),\n",
    "            parameters={\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The location or weather query to process\"\n",
    "                }\n",
    "            },\n",
    "            required=[\"query\"]\n",
    "        )\n",
    "        return [weather_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Setup and run the weather agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup_and_run_agent function is designed to process weather queries using the WeatherAgent directly, bypassing the Agent SDK framework due to compatibility issues. Here's a description of its functionality:\n",
    "\n",
    "This function serves as a simplified interface for processing weather queries when the standard Agent SDK approach encounters issues. It:\n",
    "\n",
    "1. Creates a WeatherMCPServer instance (though this isn't actually used in the function)\n",
    "2. Initializes a new WeatherAgent with the necessary API keys\n",
    "3. Directly processes the user's query through the agent's process_weather_query method\n",
    "4. Returns the generated response\n",
    "\n",
    "The *persistent_weather_agent* declaration that follows creates a single, long-lived instance of the WeatherAgent that maintains conversation context across multiple queries. This is crucial for handling follow-up questions that rely on previous context, such as \"How about in London?\" or \"Is it warmer than yesterday?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set up and run the agent with MCP\n",
    "async def setup_and_run_agent(user_query):\n",
    "    # Create the MCP server with your weather tool\n",
    "    weather_server = WeatherMCPServer()\n",
    "    \n",
    "\n",
    "    weather_agent = WeatherAgent(\n",
    "        weather_api_key=WEATHER_API_KEY,\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    \n",
    "    # Process the query directly using our weather agent\n",
    "    response = weather_agent.process_weather_query(user_query)\n",
    "    \n",
    "    # Return the response\n",
    "    return response\n",
    "persistent_weather_agent = WeatherAgent(\n",
    "    weather_api_key=WEATHER_API_KEY,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle running the agent in different environments\n",
    "def get_weather_from_agent(query):\n",
    "    \"\"\"\n",
    "    Process a weather query using our weather agent directly\n",
    "    \"\"\"\n",
    "    # Use the persistent agent to maintain context between queries\n",
    "    return persistent_weather_agent.process_weather_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: What's the weather like in New York today?\n",
      "Hey there! If you're stepping out in New York today, you can expect partly cloudy skies with a temperature of 6°C, but it might feel a bit cooler at 1°C due to the wind chill. The humidity is at a comfortable 28%, so it won't feel too muggy. The wind is blowing at a brisk pace of 35 km/h, so hold onto your hat! The cloud coverage is at 50%, so you might catch a glimpse of the sun peeking through the clouds. Enjoy your day in the Big Apple!\n",
      "\n",
      "Query 2: How about in London?\n",
      "Oh, London is looking lovely today! The current temperature is a comfortable 12 degrees Celsius, but it feels slightly cooler at 11 degrees with a gentle breeze of 10 km/h. The humidity is at a comfortable 44%, so it's not too muggy. The skies are clear with no clouds in sight, making it a perfect day to go for a stroll or enjoy some outdoor activities. Don't forget to grab a light jacket before heading out to enjoy the beautiful weather in the United Kingdom's capital city!\n",
      "\n",
      "Query 3: Is it warmer than yesterday?\n",
      "Hey there! If you're wondering whether it's warmer than yesterday in London, today the temperature is 12°C, with a real feel of 11°C. The skies are clear, and the humidity is at a comfortable 44%. The wind speed is 10 km/h, with no clouds in sight. \n",
      "\n",
      "Compared to yesterday, the temperature is actually a bit cooler today, but not by much! So, grab a light jacket and enjoy the pleasant weather in London!\n",
      "\n",
      "Query 4: Will I need an umbrella tomorrow?\n",
      "Hey there! Tomorrow in London, the weather is looking pretty good. With a temperature of 12°C and low humidity at 44%, it's going to feel quite comfortable outside. The skies are expected to be clear with no cloudiness in sight. The wind speed is around 10 mph, so it might be a bit breezy.\n",
      "\n",
      "As for whether you'll need an umbrella, it looks like the chances of rain are low with the clear skies and no precipitation in the forecast. So, you can probably leave that umbrella at home and enjoy a nice day out tomorrow in London!\n"
     ]
    }
   ],
   "source": [
    "# Process a series of queries to demonstrate functionality\n",
    "queries = [\n",
    "    \"What's the weather like in New York today?\",\n",
    "    \"How about in London?\",\n",
    "    \"Is it warmer than yesterday?\",\n",
    "    \"Will I need an umbrella tomorrow?\"\n",
    "]\n",
    "\n",
    "# Process each query using the MCP agent\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    result = get_weather_from_agent(query)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
